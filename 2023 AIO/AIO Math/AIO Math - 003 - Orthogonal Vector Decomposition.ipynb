{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb5cd904",
   "metadata": {},
   "source": [
    "Daily Math Theory - Published on Monday 17th April, 2023\n",
    "\n",
    "# 3. Orthogonal Vector Decomposition\n",
    "(Phân tích Vector trực giao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ddbdd",
   "metadata": {},
   "source": [
    "### Projections\n",
    "One of the major uses of the dot product is to let us `project` one vector in the direction of another. Conceptually, we are looking at the “shadow” of one vector projected onto another, sort of like in the case of a sundial.\n",
    "\n",
    "![Image of Vector](../../images/VectorProjection.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6e28a",
   "metadata": {},
   "source": [
    "## Concept 1 - What is the decomposition a vector (or matrix)?\n",
    "*Decomposing* a vector (or matrix) means to break up that vector (or matrix) into multiple simpler pieces.\n",
    "\n",
    "In this section, we will break up a vector into two seperate vectors, one is <u>orthogonal</u> to a reference vector while the other is <u>parallel</u> to that reference vector. This action is so-called <u>orthogonal vector decomposition</u>.\n",
    "\n",
    "### Problem: Find the orthogonal projection vector\n",
    "Given two vectors $a$ and $b$ in standard position, our goal is find the point on $a$ that as close as possible to the head of $b$. We could also express this as an optimization problem: project vector $b$ onto vector $a$ such that the projection distant is minimized. Of course, that point on $a$ will be a scaled version of $a$ ; in other words, $\\beta a$. So now our goal is to find the scalar $\\beta$\n",
    "\n",
    "![Image of Vector](../../images/Vector5.PNG)\n",
    "\n",
    "We can use vector subtraction to define the line from $b$ to $\\beta a$, or give this line its own letter, $c$, but the subtraction is necessary for discovering the solution. The key insight that leads to the solution of this problem is the point that is closest to the head of $b$ is found by drawing a line from $b$ that meet $a$ at a light angle. Then, we have deduced that $(b − \\beta a)$ is orthogonal to $\\beta a$, so $a^⊤(b − \\beta a) = 0$. We will use distributive property and scalar multiplication property of the dot product to find $\\beta$\n",
    "\n",
    "$a^⊤(b − \\beta a) = 0$\n",
    "\n",
    "⇔ $a^⊤b − a^⊤(\\beta a) = 0$\n",
    "\n",
    "⇔ $a^⊤b − \\beta · a^⊤a = 0$\n",
    "\n",
    "⇔ $\\beta = \\displaystyle\\frac{a^⊤b}{a^⊤a}$\n",
    "\n",
    "$a^⊤b$ is the dot product of vector $a$ and $b$ then it is a number.\n",
    "\n",
    "$a^⊤a$ is the same then $\\beta$, is a number.\n",
    "\n",
    "This projection of vectot $b$ onto vector $a$ is called orthogonal projection.\n",
    "\n",
    "\n",
    "### Problem: Orthogonal vector decomposition\n",
    "The following section is about orthogonal vector decomposition.\n",
    "\n",
    "Given two vector, one’s called \"target vector\", the other’s called \"reference vector\". Our goal is to decompose the target vector into two vectors such that (1) those two vectors sum to the target vector, and (2) one vector is orthogonal to the reference vector while the other is parallel to the reference vector. Whereas,\n",
    "\n",
    "`t` is target vector\n",
    "\n",
    "`r` is reference vector.\n",
    "\n",
    "The two vectors formed from target vector will be perpendicular (vuông góc) component and parallel component.\n",
    "\n",
    "$t\\bot r$ is the perpendicular component\n",
    "\n",
    "$t\\|r$ is the parallel component\n",
    "\n",
    "![Image of Vector](../../images/Vector6.PNG)\n",
    "\n",
    "Applying orthogonal projection vector $t$ auto vector $r$, then we have\n",
    "\n",
    "$t\\|r = r.\\displaystyle\\frac{t^⊤r}{r^⊤r}$\n",
    "\n",
    "\n",
    "Note the subtle difference to Equation 2-12: there we only computed the scalar $\\beta$; here we want to compute the scaled vector $\\beta r$. That’s the parrel component $t\\|r$. To find the perpendicular component, we already know that the two vector components must sum to the target vector.\n",
    "\n",
    "Thus\n",
    "\n",
    "$t$ = $t\\bot r$ + $t\\|r \\Leftrightarrow t\\bot r$ = t − $t\\|r$\n",
    "\n",
    "$t$ and $t\\|r$ is already know to find $t\\bot r$ , the perpendicular component (thành phần vuông góc). We finally find out the two component $t\\bot r$, $t\\|r$ and be able to end the \"Orthogonal vector decomposition\" here. But is that perpendicular component really orthogonal’ to the reference vector?\n",
    "\n",
    "Yes, to prove it, you need to show that the dot product between the perpendicular component and the the reference vector is zero\n",
    "\n",
    "$(t\\bot r)^Tr$ = $\\begin{pmatrix}t − r \\displaystyle\\frac{t^⊤r}{r^⊤r}\\end{pmatrix}^⊤r$ = $t^⊤r − r^⊤r \\displaystyle\\frac{t^⊤r}{r^⊤r}$ = $t^⊤r − t^⊤r$ = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a35f56",
   "metadata": {},
   "source": [
    "## Concept 2 - Summary\n",
    "* A vector is an ordered list of numbers that is placed in a column or in a row. The number of elements in a vector is called its dimensionality, and a vector can be represented as a line in a geometric space with the number of axes equal to the dimensionality.\n",
    "* Several arithmetic operations (addition, subtraction, and Hadamard multiplication) on vectors work element-wise.\n",
    "* The dot product is a single number that encodes the relationship between two vectors of the same dimensionality, and is computed as element-wise multiplication and sum.\n",
    "* The dot product is zero for vectors that are orthogonal, which geometrically means that the vectors meet at a right angle.\n",
    "* Orthogonal vector decomposition involves breaking up a vector into the sum of two other vectors that are orthogonal and parallel to a reference vector. The formula for this decomposition can be rederived from the geometry, but you should remember the phrase “mapping over magnitude” as the concept that thatformula expresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d48f234",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] M. Cohen, Practical linear algebra for data science: From core concepts to applications using Python. O’Reilly Media, 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b94750",
   "metadata": {},
   "source": [
    "## Vectơ trực giao là gì? \n",
    "Theo thuật ngữ toán học, từ trực giao có nghĩa là hướng vào một góc 90 °. Hai vectơ u, v trực giao với nhau nếu chúng vuông góc, tức là chúng tạo thành một góc vuông, hoặc nếu tích chấm mà chúng mang lại bằng không.\n",
    "\n",
    "$a\\cdot b = |a||b| cos \\theta$                                           `(4)`\n",
    "\n",
    "2 vector vuông góc nên $cos \\theta$ = 0 nên $a\\cdot b = 0$\n",
    "\n",
    "Xem lại bài AIO Math - 002 - Dot Product and Mutiplications - Concept 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163bfb74",
   "metadata": {},
   "source": [
    "# Excises\n",
    "\n",
    "In this assignment, you will be asked to calculate the orthogonal projection vector and two component of orthogonal vector decomposition of two given vectors.\n",
    "\n",
    "You can use any Python libraries, such as NumPy, SymPy, etc., to solve the questions.\n",
    "\n",
    "**Hint**\n",
    "\n",
    "If you are using NumPy, you can use the following functions:\n",
    "* `np.dot` function to calculate the dot product of two vectors.\n",
    "* `np.tranpose` function can be used to tranpose vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed1810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9768a",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "![Image of Vector](../../images/Vector-question1.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1146eefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta is 0.6557226793951164\n",
      "t_paralllel_r is [2.99857767e-08 2.67749602e-08 4.77967671e-06]\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "t = np.array([1.1298561936e-4, 2.1295619391e-5, 3.951893759e-6])\n",
    "r = np.array([4.57293572935e-8, 4.083275e-8, 7.289174e-6])\n",
    "\n",
    "beta = np.dot(r,t) / np.dot(r, r)\n",
    "betar = np.multiply(beta, r)\n",
    "\n",
    "print (f\"beta is { beta }\")\n",
    "print ( f\"t_paralllel_r is { betar }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d1cc207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta is 4.595931845762303\n",
      "t_paralllel_r is [2.63317356e-08 3.82726224e-09 1.32902400e-06 7.42258614e-07]\n"
     ]
    }
   ],
   "source": [
    "# b)\n",
    "t = np.array([0.1298561936e-4, 0.1295619391e-5, 0.951893759e-6, 0.95112189659169e-6])\n",
    "r = np.array([0.57293572935e-8, 0.083275e-8, 0.289174e-6, 0.1615033988e-6])\n",
    "\n",
    "beta = np.dot(r,t) / np.dot(r, r)\n",
    "betar = np.multiply(beta, r)\n",
    "\n",
    "print (f\"beta is { beta }\")\n",
    "print ( f\"t_paralllel_r is { betar }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10b57775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta is 1.0176292948508874\n",
      "t_paralllel_r is [5.83035440e-09 8.47430795e-10 2.94271934e-07 1.64350590e-07\n",
      " 1.58947498e-06 9.68674975e-07 9.67889505e-07 1.31846025e-06\n",
      " 1.92714464e-07 9.67889505e-07]\n"
     ]
    }
   ],
   "source": [
    "# c) \n",
    "t = np.array([0.1298561936e-4, 0.1295619391e-5, 0.951893759e-6, 0.95112189659169e-6, 0.1295619391e-5, 0.951893759e-6, 0.95112189659169e-6, 0.1295619391e-5, 0.951893759e-6, 0.95112189659169e-6])\n",
    "r = np.array([0.572935e-8, 0.083275e-8, 0.289174e-6, 0.1615033988e-6, 0.15619391e-5, 0.951893759e-6, 0.95112189659169e-6, 0.1295619391e-5, 0.1893759e-6, 0.95112189659169e-6])\n",
    "\n",
    "beta = np.dot(r,t) / np.dot(r, r)\n",
    "betar = np.multiply(beta, r)\n",
    "\n",
    "print (f\"beta is { beta }\")\n",
    "print ( f\"t_paralllel_r is { betar }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad84345b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta is 0.6557226793951164\n",
      "t_paralllel_r is [3.05129589e-11 4.43499987e-12 1.54006203e-09 8.60123149e-10\n",
      " 6.01730660e-07 1.13414673e-07 2.10467107e-08 8.31846257e-09\n",
      " 5.06952710e-09 5.06541638e-09 6.90011628e-09 1.00856451e-09\n",
      " 5.06541638e-09 8.28406263e-11 1.10681992e-10 1.54251841e-04\n",
      " 1.59858847e-07 2.29634659e-10 7.10123924e-05 1.22013506e-11\n",
      " 3.11896618e-11 1.12417035e-10 1.10144296e-05 3.38843374e-05\n",
      " 3.04469513e-05 1.61985315e-04 3.24133394e-05 2.83724093e-05\n",
      " 1.36172497e-05 1.61026957e-06 2.10467107e-08 6.91578747e-08\n",
      " 6.90011628e-09 5.06952710e-09 5.06541638e-09 6.90011628e-09\n",
      " 5.06952710e-09 5.06541638e-09 6.90011628e-09 5.06952710e-09\n",
      " 5.06541638e-09 2.75921763e-03 2.89727451e-06 1.77607916e-07\n",
      " 3.46052008e-06]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_beta (t , r ):\n",
    "    return np.dot(r , t ) / np.dot(r , r )\n",
    "\n",
    "t = np.array([1.1298561936e-4 ,2.1295619391e-5 ,3.951893759e-6])\n",
    "r = np.array([4.57293572935e-8 ,4.083275e-8 ,7.289174e-6])\n",
    "\n",
    "beta = compute_beta(t , r) # Compute beta\n",
    "t_paralllel_r = np.multiply(beta , r) # Compute the parallel component (or thogonal projection vector )\n",
    "\n",
    "print (f\"beta is { beta }\")\n",
    "print ( f\"t_paralllel_r is { t_parallel_r }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc1fc3",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "![Image of Vector](../../images/Vector-Question2.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f2cc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel:  [2.99857767e-08 2.67749602e-08 4.77967671e-06]\n",
      "perpendicular:  [ 1.12955634e-04  2.12688444e-05 -8.27782947e-07]\n"
     ]
    }
   ],
   "source": [
    "# a)\n",
    "t = np.array([1.1298561936e-4, 2.1295619391e-5, 3.951893759e-6])\n",
    "r = np.array([4.57293572935e-8, 4.083275e-8, 7.289174e-6])\n",
    "\n",
    "beta = np.dot(np.transpose(r),t) / np.dot(np.transpose(r), r)\n",
    "𝑡_parallel_𝑟 = np.multiply(beta, r)\n",
    "𝑡_perpendicular_𝑟 = t - 𝑡_parallel_𝑟\n",
    "print(\"parallel: \", 𝑡_parallel_𝑟)\n",
    "print(\"perpendicular: \", 𝑡_perpendicular_𝑟)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "650a3482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel:  [1.63989192e-07 1.54383260e-07 1.58225635e-05 1.56304443e-05]\n",
      "perpendicular:  [ 1.01282163e-03  1.01141236e-04 -4.87066970e-06 -6.69461674e-06]\n"
     ]
    }
   ],
   "source": [
    "# b) \n",
    "t = np.array([10.1298561936e-4, 10.1295619391e-5, 10.951893759e-6, 8.9358275112189659169e-6])\n",
    "r = np.array([8.5358277293572935e-8, 8.03582783275e-8, 8.23582789174e-6, 8.135827615033988e-6])\n",
    "\n",
    "beta = np.dot(np.transpose(r),t) / np.dot(np.transpose(r), r)\n",
    "𝑡_parallel_𝑟 = np.multiply(beta, r)\n",
    "𝑡_perpendicular_𝑟 = t - 𝑡_parallel_𝑟\n",
    "print(\"parallel: \", 𝑡_parallel_𝑟)\n",
    "print(\"perpendicular: \", 𝑡_perpendicular_𝑟)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30f553be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta is 1.0176292948508874\n",
      "t_paralllel_r is [5.83035440e-09 8.47430795e-10 2.94271934e-07 1.64350590e-07\n",
      " 1.58947498e-06 9.68674975e-07 9.67889505e-07 1.31846025e-06\n",
      " 1.92714464e-07 9.67889505e-07]\n",
      "t_perp_r is [ 1.29797890e-05  1.29477196e-06  6.57621825e-07  7.86771307e-07\n",
      " -2.93855594e-07 -1.67812157e-08 -1.67676084e-08 -2.28408563e-08\n",
      "  7.59179295e-07 -1.67676084e-08]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_beta (t , r ):\n",
    "    return np.dot(r , t ) / np.dot(r , r )\n",
    "\n",
    "t = np.array([0.1298561936e-4,0.1295619391e-5,0.951893759e-6,0.95112189659169e-6,0.1295619391e-5,0.951893759e-6,0.95112189659169e-6,0.1295619391e-5,0.951893759e-6,0.95112189659169e-6])\n",
    "r = np.array([0.572935e-8,0.083275e-8,0.289174e-6,0.1615033988e-6,0.15619391e-5,0.951893759e-6,0.95112189659169e-6,0.1295619391e-5,0.1893759e-6,0.95112189659169e-6])\n",
    "\n",
    "beta = compute_beta (t , r ) # Compute beta\n",
    "t_parallel_r = np . multiply ( beta , r ) # Compute the parallel component (or orthogonal projection vector )\n",
    "t_perp_r = t - t_parallel_r # Compute the perpendicular component\n",
    "\n",
    "print ( f\"beta is { beta }\")\n",
    "print ( f\"t_paralllel_r is { t_parallel_r }\")\n",
    "print ( f\"t_perp_r is { t_perp_r }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e4ef51",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "![Image of Vector](../../images/Vector-question3.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc79d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.array([1.1298561936e-4,\n",
    "              2.1295619391e-5,\n",
    "              3.951893759e-6,\n",
    "              0.1298561936e-4,\n",
    "              0.1295619391e-5,\n",
    "              0.951893759e-6,\n",
    "              0.95112189659169e-6,\n",
    "              0.1295619391e-5,\n",
    "              0.951893759e-6,\n",
    "              0.95112189659169e-6,\n",
    "              0.1295619391e-5,\n",
    "              0.951893759e-6,\n",
    "              0.95112189659169e-6,\n",
    "              0.51809212e-0,\n",
    "              0.12577355e-3,\n",
    "              0.38112871e-1,\n",
    "              0.59678991e-7,\n",
    "              0.61551359e-3,\n",
    "              0.54401475e-3,\n",
    "              0.33349041e-4,\n",
    "              0.64977411e-3,\n",
    "              0.50102406e-3,\n",
    "              0.38099996e-4,\n",
    "              0.15541389e-1,\n",
    "              0.17227333e-3,\n",
    "              0.38736404e-3,\n",
    "              0.47759981e-3,\n",
    "              0.05644438e-5,\n",
    "              0.39477794e-1,\n",
    "              0.33361011e-4,\n",
    "              0.4377816e-3,\n",
    "              0.37424289e-3,\n",
    "              0.43360232e-7,\n",
    "              0.21229984e-3,\n",
    "              0.46652962e-7,\n",
    "              0.03184187e-7,\n",
    "              0.40135214e-1,\n",
    "              0.00515292e-3,\n",
    "              0.10548878e-1,\n",
    "              0.21545098e-3,\n",
    "              0.33967468e-3,\n",
    "              0.219416e-3,\n",
    "              0.44649316e-9,\n",
    "              0.44517355e-3,\n",
    "              0.28901043e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe07c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array([0.572935e-8,\n",
    "              0.083275e-8,\n",
    "              0.289174e-6,\n",
    "              0.1615033988e-6,\n",
    "              1.1298561936e-4,\n",
    "              2.1295619391e-5,\n",
    "              3.951893759e-6,\n",
    "              0.15619391e-5,\n",
    "              0.951893759e-6,\n",
    "              0.95112189659169e-6,\n",
    "              0.1295619391e-5,\n",
    "              0.1893759e-6,\n",
    "              0.95112189659169e-6,\n",
    "              0.15554799e-7,\n",
    "              0.2078251e-7,\n",
    "              0.28963523e-1,\n",
    "              0.30016338e-4,\n",
    "              0.43117986e-7,\n",
    "              0.13333838e-1,\n",
    "              0.22910203e-8,\n",
    "              0.05856413e-7,\n",
    "              0.21108295e-7,\n",
    "              0.20681548e-2,\n",
    "              0.63623862e-2,\n",
    "              0.57169559e-2,\n",
    "              0.3041562e-1,\n",
    "              0.60861802e-2,\n",
    "              0.53274238e-2,\n",
    "              0.25568805e-2,\n",
    "              0.302356713e-3,\n",
    "              3.951893759e-6,\n",
    "              0.1298561936e-4,\n",
    "              0.1295619391e-5,\n",
    "              0.951893759e-6,\n",
    "              0.95112189659169e-6,\n",
    "              0.1295619391e-5,\n",
    "              0.951893759e-6,\n",
    "              0.95112189659169e-6,\n",
    "              0.1295619391e-5,\n",
    "              0.951893759e-6,\n",
    "              0.95112189659169e-6,\n",
    "              0.51809212e-0,\n",
    "              0.54401475e-3,\n",
    "              0.33349041e-4,\n",
    "              0.64977411e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6ca10c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel:  [3.05129589e-11 4.43499987e-12 1.54006203e-09 8.60123149e-10\n",
      " 6.01730660e-07 1.13414673e-07 2.10467107e-08 8.31846257e-09\n",
      " 5.06952710e-09 5.06541638e-09 6.90011628e-09 1.00856451e-09\n",
      " 5.06541638e-09 8.28406263e-11 1.10681992e-10 1.54251841e-04\n",
      " 1.59858847e-07 2.29634659e-10 7.10123924e-05 1.22013506e-11\n",
      " 3.11896618e-11 1.12417035e-10 1.10144296e-05 3.38843374e-05\n",
      " 3.04469513e-05 1.61985315e-04 3.24133394e-05 2.83724093e-05\n",
      " 1.36172497e-05 1.61026957e-06 2.10467107e-08 6.91578747e-08\n",
      " 6.90011628e-09 5.06952710e-09 5.06541638e-09 6.90011628e-09\n",
      " 5.06952710e-09 5.06541638e-09 6.90011628e-09 5.06952710e-09\n",
      " 5.06541638e-09 2.75921763e-03 2.89727451e-06 1.77607916e-07\n",
      " 3.46052008e-06]\n",
      "perpendicular:  [ 1.12985589e-04  2.12956150e-05  3.95035370e-06  1.29847592e-05\n",
      "  6.93888731e-07  8.38479086e-07  9.30075186e-07  1.28730093e-06\n",
      "  9.46824232e-07  9.46056480e-07  1.28871927e-06  9.50885194e-07\n",
      "  9.46056480e-07  5.18092120e-01  1.25773439e-04  3.79586192e-02\n",
      " -1.00179856e-07  6.15513360e-04  4.73002358e-04  3.33490288e-05\n",
      "  6.49774079e-04  5.01023948e-04  2.70855664e-05  1.55075047e-02\n",
      "  1.41826379e-04  2.25378725e-04  4.45186471e-04 -2.78079655e-05\n",
      "  3.94641768e-02  3.17507414e-05  4.37760553e-04  3.74173732e-04\n",
      "  3.64601157e-08  2.12294770e-04  4.15875456e-08 -3.71592928e-09\n",
      "  4.01352089e-02  5.14785458e-06  1.05488711e-02  2.15445910e-04\n",
      "  3.39669615e-04 -2.53980163e-03 -2.89682801e-06  4.44995942e-04\n",
      "  2.85549910e-04]\n"
     ]
    }
   ],
   "source": [
    "beta = np.dot(np.transpose(r),t) / np.dot(np.transpose(r), r)\n",
    "𝑡_parallel_𝑟 = np.multiply(beta, r)\n",
    "𝑡_perpendicular_𝑟 = t - 𝑡_parallel_𝑟\n",
    "print(\"parallel: \", 𝑡_parallel_𝑟)\n",
    "print(\"perpendicular: \", 𝑡_perpendicular_𝑟)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
